{"metadata":{"colab":{"provenance":[{"file_id":"11e8ZirEhEEhZj7pNZmB8r_dPDEwRnfPR","timestamp":1671051831339},{"file_id":"1SoZM3Yq8C8BdYu-st3_BAlhze2_Z6Ilb","timestamp":1668798742100},{"file_id":"1U6q6WFOo7_Ka_C9cdq49KwAsI_lFX86-","timestamp":1668698832849},{"file_id":"1h6rKqbyzegmvnh5T6X1MhTFOXE6VUciq","timestamp":1666209449412},{"file_id":"1Vz66UR_ImIhJ4HEkCzdY_9E9QLKiboV1","timestamp":1663780048645}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Waze Project**\n**Course 2 - Get Started with Python**","metadata":{"id":"DtNBZFHO3M7n"}},{"cell_type":"markdown","source":"Welcome to the Waze Project!\n\nYour Waze data analytics team is still in the early stages of their user churn project. Previously, you were asked to complete a project proposal by your supervisor, May Santner. You have received notice that your project proposal has been approved and that your team has been given access to Waze's user data. To get clear insights, the user data must be inspected and prepared for the upcoming process of exploratory data analysis (EDA).\n\nA Python notebook has been prepared to guide you through this project. Answer the questions and create an executive summary for the Waze data team.","metadata":{"id":"zJCatj3xzrQZ"}},{"cell_type":"markdown","source":"# **Course 2 End-of-course project: Inspect and analyze data**\n\nIn this activity, you will examine data provided and prepare it for analysis. This activity will help ensure the information is,\n\n1.   Ready to answer questions and yield insights\n\n2.   Ready for visualizations\n\n3.   Ready for future hypothesis testing and statistical methods\n<br/>\n\n**The purpose** of this project is to investigate and understand the data provided.\n\n**The goal** is to use a dataframe contructed within Python, perform a cursory inspection of the provided dataset, and inform team members of your findings.\n<br/>\n\n*This activity has three parts:*\n\n**Part 1:** Understand the situation\n* How can you best prepare to understand and organize the provided information?\n\n**Part 2:** Understand the data\n\n* Create a pandas dataframe for data learning, future exploratory data analysis (EDA), and statistical activities\n\n* Compile summary information about the data to inform next steps\n\n**Part 3:** Understand the variables\n\n* Use insights from your examination of the summary data to guide deeper investigation into variables\n\n\n<br/>\n\nFollow the instructions and answer the following questions to complete the activity. Then, you will complete an Executive Summary using the questions listed on the PACE Strategy Document.\n\nBe sure to complete this activity before moving on. The next course item will provide you with a completed exemplar to compare to your own work.\n\n","metadata":{"id":"rgSbVJvomcVa"}},{"cell_type":"markdown","source":"# **Identify data types and compile summary information**\n","metadata":{"id":"HjFGokxv2pc5"}},{"cell_type":"markdown","source":"<img src=\"images/Pace.png\" width=\"100\" height=\"100\" align=left>\n\n# **PACE stages**","metadata":{"id":"MRUYfzCb4vop"}},{"cell_type":"markdown","source":"Throughout these project notebooks, you'll see references to the problem-solving framework, PACE. The following notebook components are labeled with the respective PACE stages: Plan, Analyze, Construct, and Execute.","metadata":{"id":"b4B47DQPcSQu"}},{"cell_type":"markdown","source":"<img src=\"images/Plan.png\" width=\"100\" height=\"100\" align=left>\n\n\n## **PACE: Plan**\n\nConsider the questions in your PACE Strategy Document and those below to craft your response:","metadata":{"id":"zRHb2QQWj99m"}},{"cell_type":"markdown","source":"### **Task 1. Understand the situation**\n\n*   How can you best prepare to understand and organize the provided driver data?\n\n\n*Begin by exploring your dataset and consider reviewing the Data Dictionary.*","metadata":{"id":"pWEfG5zJV5oG"}},{"cell_type":"markdown","source":"==> ENTER YOUR RESPONSE HERE","metadata":{"id":"irvqnKSe6Z80"}},{"cell_type":"markdown","source":"<img src=\"images/Analyze.png\" width=\"100\" height=\"100\" align=left>\n\n## **PACE: Analyze**\n\nConsider the questions in your PACE Strategy Document to reflect on the Analyze stage.","metadata":{"id":"1E9Y5aC0IAA-"}},{"cell_type":"markdown","source":"### **Task 2a. Imports and data loading**\n\nStart by importing the packages that you will need to load and explore the dataset. Make sure to use the following import statements:\n\n*   `import pandas as pd`\n\n*   `import numpy as np`\n","metadata":{"id":"D4WK_AxP_S__"}},{"cell_type":"code","source":"# Import packages for data manipulation\nimport pandas as pd\nimport numpy as np\n","metadata":{"id":"OZSXM4q5zrQh","execution":{"iopub.status.busy":"2024-09-04T17:03:42.900072Z","iopub.execute_input":"2024-09-04T17:03:42.900477Z","iopub.status.idle":"2024-09-04T17:03:43.303724Z","shell.execute_reply.started":"2024-09-04T17:03:42.900438Z","shell.execute_reply":"2024-09-04T17:03:43.302635Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Then, load the dataset into a dataframe. Creating a dataframe will help you conduct data manipulation, exploratory data analysis (EDA), and statistical activities.\n\n**Note:** As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions.","metadata":{"id":"2-hT-EQA67v3"}},{"cell_type":"code","source":"# Load dataset into dataframe\ndf = pd.read_csv('waze_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-04T17:03:47.555066Z","iopub.execute_input":"2024-09-04T17:03:47.555695Z","iopub.status.idle":"2024-09-04T17:03:48.342365Z","shell.execute_reply.started":"2024-09-04T17:03:47.555655Z","shell.execute_reply":"2024-09-04T17:03:48.340875Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load dataset into dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwaze_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'waze_dataset.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'waze_dataset.csv'","output_type":"error"}]},{"cell_type":"markdown","source":"### **Task 2b. Summary information**\n\nView and inspect summary information about the dataframe by **coding the following:**\n\n1.   df.head(10)\n2.   df.info()\n\n*Consider the following questions:*\n\n1. When reviewing the `df.head()` output, are there any variables that have missing values?\n\n2. When reviewing the `df.info()` output, what are the data types? How many rows and columns do you have?\n\n3. Does the dataset have any missing values?","metadata":{"id":"gYx1emvno7U_"}},{"cell_type":"code","source":"### YOUR CODE HERE ###\ndf.head(10)","metadata":{"id":"t7Nck2hh4R6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### YOUR CODE HERE ###\ndf.info()","metadata":{"id":"3NctoTSAvGGD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"==> ENTER YOUR RESPONSES TO QUESTIONS 1-3 HERE\n\n1.None of the variables in the first 10 observations have missing values.\n\n2.The Varibles label and device are type object; total_sessions, driven_km_drives, and duration_minutes_drives are type float64; the rest of the varibles are type int64. There are 14,999 rows and 13 columns\n\n3.The dataset has 700 missing values in the label column","metadata":{"id":"JscqNfr6ZVsE"}},{"cell_type":"markdown","source":"### **Task 2c. Null values and summary statistics**\n\nCompare the summary statistics of the 700 rows that are missing labels with summary statistics of the rows that are not missing any values.\n\n**Question:** Is there a discernible difference between the two populations?\n","metadata":{"id":"BMNnIoc51_1N"}},{"cell_type":"code","source":"# Isolate rows with null values\nnull_df= df[df['label'].isnull()]\n\n# Display summary stats of rows with null values\nnull_df.describe()\n","metadata":{"id":"bAQeHW-d2S1-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Isolate rows without null values\nnot_null_df = df[~df['label'].isnull()]\n\n# Display summary stats of rows without null values\nnot_null_df.describe()","metadata":{"id":"W77hp8q3w-zi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"==> ENTER YOUR RESPONSE HERE\n\n1.Comparing summary statistics of the observation with missing retention labels with those that arent missing any values reveal nothing remarkable. The means and standard deviations are fairly consistent between the two groups","metadata":{"id":"sJpXfBZUlWC5"}},{"cell_type":"markdown","source":"### **Task 2d. Null values - device counts**\n\nNext, check the two populations with respect to the `device` variable.\n\n**Question:** How many iPhone users had null values and how many Android users had null values?","metadata":{"id":"S2CupDgSlpm4"}},{"cell_type":"code","source":"# Get count of null values by device\nnull_df['device'].value_counts()","metadata":{"id":"IbCnokO8lsq3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"==> ENTER YOUR RESPONSE HERE\n\n1.Of the 700 rows with null values, 447 were iPhone users and 253 were Android users","metadata":{"id":"JKfLfQQUltQk"}},{"cell_type":"markdown","source":"Now, of the rows with null values, calculate the percentage with each device&mdash;Android and iPhone. You can do this directly with the [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) function.","metadata":{"id":"xodMNO1Ql5PZ"}},{"cell_type":"code","source":"# Calculate % of iPhone nulls and Android nulls\nnull_df['device'].value_counts(normalize=True)","metadata":{"id":"ajlCljYHmCTa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"How does this compare to the device ratio in the full dataset?","metadata":{"id":"dA_ps_fA3xn9"}},{"cell_type":"code","source":"# Calculate % of iPhone users and Android users in full dataset\ndf['device'].value_counts(normalize=True)\n","metadata":{"id":"Dm-qKyQNmCsQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The percentage of missing values by each device is consistent with their representation in the data overall.\n\nThere is nothing to suggest a non-random cause of the missing data.","metadata":{"id":"eEIeGZdgmRh9"}},{"cell_type":"markdown","source":"Examine the counts and percentages of users who churned vs. those who were retained. How many of each group are represented in the data?","metadata":{"id":"uIzg4fXtmSTe"}},{"cell_type":"code","source":"# Calculate counts of churned vs. retained\nprint(df['label'].value_counts())\nprint()\nprint(df['label'].value_counts(normalize=True))\n\n","metadata":{"id":"zQ1mu8g9maYX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This dataset contains 82% retained users and 18% churned users.\n\nNext, compare the medians of each variable for churned and retained users. The reason for calculating the median and not the mean is that you don't want outliers to unduly affect the portrayal of a typical user. Notice, for example, that the maximum value in the `driven_km_drives` column is 21,183 km. That's more than half the circumference of the earth!","metadata":{"id":"VYTZIIOKmfIz"}},{"cell_type":"code","source":"# Calculate median values of all columns for churned and retained users\ndf.groupby('label').median(numeric_only=True)\n","metadata":{"id":"jzngebHRmmFA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This offers an interesting snapshot of the two groups, churned vs. retained:\n\nUsers who churned averaged ~3 more drives in the last month than retained users, but retained users used the app on over twice as many days as churned users in the same time period.\n\nThe median churned user drove ~200 more kilometers and 2.5 more hours during the last month than the median retained user.\n\nIt seems that churned users had more drives in fewer days, and their trips were farther and longer in duration. Perhaps this is suggestive of a user profile. Continue exploring!","metadata":{"id":"NvnPFKS3mm71"}},{"cell_type":"markdown","source":"Calculate the median kilometers per drive in the last month for both retained and churned users.\n\nBegin by dividing the `driven_km_drives` column by the `drives` column. Then, group the results by churned/retained and calculate the median km/drive of each group.","metadata":{"id":"cUAkU-JInALK"}},{"cell_type":"code","source":"# Add a column to df called `km_per_drive`\ndf['km_per_drive'] = df['driven_km_drives'] / df['drives']\n\n# Group by `label`, calculate the median, and isolate for km per drive\nmedian_km_per_drive = df.groupby('label').median(numeric_only=True)[['km_per_drive']]\nmedian_km_per_drive","metadata":{"id":"TVcP2PPhnBMZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The median retained user drove about one more kilometer per drive than the median churned user. How many kilometers per driving day was this?\n\nTo calculate this statistic, repeat the steps above using `driving_days` instead of `drives`.","metadata":{"id":"C6VicaRVnFzq"}},{"cell_type":"code","source":"# Add a column to df called `km_per_driving_day`\ndf['km_per_driving_day'] = df['driven_km_drives'] / df['driving_days']\n\n# Group by `label`, calculate the median, and isolate for km per driving day\nmedian_km_per_driving_day = df.groupby('label').median(numeric_only=True)[['km_per_driving_day']]\nmedian_km_per_driving_day","metadata":{"id":"I6lD33kfnGQb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, calculate the median number of drives per driving day for each group.","metadata":{"id":"kIfSmukAnVSs"}},{"cell_type":"code","source":"# Add a column to df called `drives_per_driving_day`\ndf['drives_per_driving_day'] = df['drives'] / df['driving_days']\n\n# Group by `label`, calculate the median, and isolate for drives per driving day\nmedian_drives_per_driving_day = df.groupby('label').median(numeric_only=True)[['drives_per_driving_day']]\nmedian_drives_per_driving_day","metadata":{"id":"VAHqOO8endWX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The median user who churned drove 698 kilometers each day they drove last month, which is almost ~240% the per-drive-day distance of retained users. The median churned user had a similarly disproporionate number of drives per drive day compared to retained users.\n\nIt is clear from these figures that, regardless of whether a user churned or not, the users represented in this data are serious drivers! It would probably be safe to assume that this data does not represent typical drivers at large. Perhaps the data&mdash;and in particular the sample of churned users&mdash;contains a high proportion of long-haul truckers.\n\nIn consideration of how much these users drive, it would be worthwhile to recommend to Waze that they gather more data on these super-drivers. It's possible that the reason for their driving so much is also the reason why the Waze app does not meet their specific set of needs, which may differ from the needs of a more typical driver, such as a commuter.","metadata":{"id":"LVRAwsb1nv2L"}},{"cell_type":"markdown","source":"Finally, examine whether there is an imbalance in how many users churned by device type.\n\nBegin by getting the overall counts of each device type for each group, churned and retained.","metadata":{"id":"xc7Q6elLoD1R"}},{"cell_type":"code","source":"# For each label, calculate the number of Android users and iPhone users\ndf.groupby(['label', 'device']).size()","metadata":{"id":"LGkODIILoEp-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, within each group, churned and retained, calculate what percent was Android and what percent was iPhone.","metadata":{"id":"yTVM6qFkoJs4"}},{"cell_type":"code","source":"# For each label, calculate the percentage of Android users and iPhone users\ndf.groupby('label')['device'].value_counts(normalize=True)\n","metadata":{"id":"rx0ElsS6oO7y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The ratio of iPhone users and Android users is consistent between the churned group and the retained group, and those ratios are both consistent with the ratio found in the overall dataset.","metadata":{"id":"DQVIMPzroavO"}},{"cell_type":"markdown","source":"<img src=\"images/Construct.png\" width=\"100\" height=\"100\" align=left>\n\n## **PACE: Construct**\n\n**Note**: The Construct stage does not apply to this workflow. The PACE framework can be adapted to fit the specific requirements of any project.\n\n","metadata":{"id":"tF_82VLgzrQm"}},{"cell_type":"markdown","source":"<img src=\"images/Execute.png\" width=\"100\" height=\"100\" align=left>\n\n## **PACE: Execute**\n\nConsider the questions in your PACE Strategy Document and those below to craft your response:","metadata":{"id":"BMHV86A6zrQo"}},{"cell_type":"markdown","source":"### **Task 3. Conclusion**\n\nRecall that your supervisor, May Santer, asked you to share your findings with the data team in an executive summary. Consider the following questions as you prepare to write your summary. Think about key points you may want to share with the team, and what information is most relevant to the user churn project.\n\n**Questions:**\n\n1. Did the data contain any missing values? How many, and which variables were affected? Was there a pattern to the missing data?\n\n2. What is a benefit of using the median value of a sample instead of the mean?\n\n3. Did your investigation give rise to further questions that you would like to explore or ask the Waze team about?\n\n4. What percentage of the users in the dataset were Android users and what percentage were iPhone users?\n\n5. What were some distinguishing characteristics of users who churned vs. users who were retained?\n\n6. Was there an appreciable difference in churn rate between iPhone users vs. Android users?\n\n\n\n","metadata":{"id":"u3HxcMZgz6iW"}},{"cell_type":"markdown","source":"==> ENTER YOUR RESPONSES TO QUESTIONS 1-6 HERE\n\n1.The dataset has 700 missing values in the label column. There was no obvious pattern to the missing values.\n\n2.Mean is subject to the influence of outliers, while the median represents the middle value of the distribution regardless of any outlying values\n\n3.Yes. For example, the median user who churned drove 698 kilometers each day they drove last month, which is about 240% the per-drive-day distance of retained users. It would be helpful to know how this data was collected and if it represents a non-random sample of users.\n\n4.Android users comprised approximately 36% of the sample, while Iphone users made up about 64%\n\n5.Generally, users who churned drove farther and longer in fewer days than retained users. They also used the app about half as many times as retained users over the same period\n\n6.No. The churn rate for both iPhone and Android users was within one percentage point of each other. There is nothing suggestive of churn being correlated with device","metadata":{"id":"iMHlK7k5_2PV"}},{"cell_type":"markdown","source":"**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged.","metadata":{}}]}